{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac305884",
   "metadata": {},
   "source": [
    "\n",
    "# Keyword spotting with DTW prototypes\n",
    "\n",
    "This notebook loads the pre-computed training/validation features and builds a\n",
    "simple Dynamic Time Warping (DTW) prototype for each keyword. The best matching\n",
    "validation instance for every keyword is exported to `submission.csv` so the\n",
    "results can be submitted to Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef695f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Make sure local helpers are on the path regardless of launch directory\n",
    "if '__file__' in globals():\n",
    "    NOTEBOOK_DIR = Path(__file__).resolve().parent\n",
    "else:\n",
    "    NOTEBOOK_DIR = Path.cwd()\n",
    "sys.path.append(str(NOTEBOOK_DIR))\n",
    "\n",
    "from keyword_search import (\n",
    "    build_submission,\n",
    "    keyword_medoid,\n",
    "    keyword_instances,\n",
    "    resample_features,\n",
    ")\n",
    "\n",
    "DATA_DIR = NOTEBOOK_DIR\n",
    "with open(DATA_DIR / \"train_features\" / \"train_db.pkl\", \"rb\") as f:\n",
    "    train_db = pickle.load(f)\n",
    "with open(DATA_DIR / \"validation_features\" / \"validation_db.pkl\", \"rb\") as f:\n",
    "    validation_db = pickle.load(f)\n",
    "\n",
    "keywords = (DATA_DIR / \"keywords.tsv\").read_text().splitlines()\n",
    "print(f\"Loaded {len(train_db)} train entries, {len(validation_db)} validation entries, {len(keywords)} keywords\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e6695c",
   "metadata": {},
   "source": [
    "\n",
    "## Prototype selection\n",
    "\n",
    "For each keyword we pick the *medoid*\u2014the instance whose average DTW distance to\n",
    "all other instances of the same keyword is minimal. Using a small Sakoe\u2013Chiba\n",
    "band keeps the alignment window narrow and reduces spurious matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a839f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = 0.1\n",
    "prototypes = {}\n",
    "medoid_stats = []\n",
    "\n",
    "for word in keywords:\n",
    "    prototype, dist_matrix = keyword_medoid(train_db, word, win_size=win_size)\n",
    "    prototypes[word] = prototype\n",
    "    medoid_stats.append({\n",
    "        \"keyword\": word,\n",
    "        \"support\": prototype.support,\n",
    "        \"mean_intra_distance\": float(dist_matrix.mean()) if dist_matrix.size > 1 else 0.0,\n",
    "    })\n",
    "\n",
    "medoid_df = pd.DataFrame(medoid_stats).sort_values(\"support\", ascending=False)\n",
    "medoid_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b620800b",
   "metadata": {},
   "source": [
    "\n",
    "## Search the validation set\n",
    "\n",
    "With the prototypes prepared we search the validation set and keep the best\n",
    "match for each keyword. The helper returns the ranked results but only the top\n",
    "match is needed for the submission file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototypes, predictions = build_submission(train_db, validation_db, keywords, win_size=win_size)\n",
    "print(f\"Collected {len(predictions)} predictions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc28a02",
   "metadata": {},
   "source": [
    "\n",
    "## Quick accuracy check\n",
    "\n",
    "This coarse check reports how many of the best matches have the correct keyword\n",
    "label in the validation annotations. It is not the Kaggle score, but it is a\n",
    "useful sanity check while iterating locally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = sum(1 for dist, loc, word, _ in predictions if word in keywords)\n",
    "accuracy = correct / len(predictions)\n",
    "print(f\"Top-1 keyword match rate: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce803bb",
   "metadata": {},
   "source": [
    "\n",
    "## Create `submission.csv`\n",
    "\n",
    "The competition expects three columns: `location`, `word`, and `distance`. The\n",
    "`distance` column contains the DTW score for the best match of that keyword in\n",
    "the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_rows = []\n",
    "for (dist, loc, word, _), keyword in zip(predictions, keywords):\n",
    "    submission_rows.append({\n",
    "        \"location\": loc,\n",
    "        \"word\": keyword,\n",
    "        \"distance\": float(dist),\n",
    "    })\n",
    "\n",
    "submission = pd.DataFrame(submission_rows)\n",
    "output_path = DATA_DIR / \"submission.csv\"\n",
    "submission.to_csv(output_path, index=False)\n",
    "output_path\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}