{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda48f2c-004d-4093-9076-01ae8eaf96f3",
   "metadata": {},
   "source": [
    "### pip installs needed (just in case of errors)\n",
    "- pip install tqdm\n",
    "- pip install pillow\n",
    "- pip install opencv-python\n",
    "- pip install scikit-image\n",
    "- pip install lxml\n",
    "- pip install regex\n",
    "- pip install pyts\n",
    "- pip install numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac305884",
   "metadata": {},
   "source": [
    "# Keyword Spotting on WashingtonDB\n",
    "\n",
    "In this notebook we implement a simple **query-by-example keyword spotting (KWS)** system on the WashingtonDB dataset.\n",
    "\n",
    "Given a list of textual **keywords**, our goal is to:\n",
    "\n",
    "1. **Choose a query example image** for each keyword from the training set.\n",
    "2. **Compute similarity scores** between this query example and candidate word images from other documents.\n",
    "3. **Find the best matching occurrence(s)** of the same word in unseen pages.\n",
    "\n",
    "The workflow is:\n",
    "\n",
    "1. **Data loading**: we use the precomputed word-level feature files (`train_db.pkl`, `validation_db.pkl`) provided for the exercise.\n",
    "2. **Keyword medoid prototype**: for each keyword, we collect all its training instances and select the **DTW medoid**, i.e. the instance with minimal average Dynamic Time Warping (DTW) distance to all other instances. This medoid acts as our **query prototype**.\n",
    "3. **Candidate filtering**: for each prototype we restrict the search to validation words with a **similar length** (±30%) to avoid comparing to obviously wrong candidates.\n",
    "4. **Similarity computation**:\n",
    "   - First, we use a cheap **Euclidean distance between mean feature vectors** to quickly filter candidates.\n",
    "   - Then, on the most promising candidates, we use the more expensive **DTW distance** as our final similarity measure.\n",
    "5. **Evaluation on validation**: for each keyword we select the **best match** in the validation set and compute a **top-1 keyword match rate** (how often we recover the correct keyword).\n",
    "6. **Submission file**: we create `submission.csv` for the Kaggle competition, where smaller distances indicate more similar (better) matches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d7b446-f727-470b-8380-446011e23291",
   "metadata": {},
   "source": [
    "### Imports and data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf27c00-ebfa-47b5-96b5-2ced1619a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DATA_DIR = C:\\Users\\MATEO\\OneDrive\\Personal\\UniFR\\Pattern Recognition\\Group7\\PR_group7\\KWS\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import DTW as dtw\n",
    "from DTW_utils import extract_word_images, find_word_image  # only used in the qualitative example\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "DATA_DIR = NOTEBOOK_DIR\n",
    "print(\"Using DATA_DIR =\", DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47550a88-36e8-457a-95e0-b794bdba5962",
   "metadata": {},
   "source": [
    "## 1. Load precomputed features and keyword list\n",
    "\n",
    "We use the provided pickled feature databases:\n",
    "\n",
    "- `train_features/train_db.pkl`\n",
    "- `validation_features/validation_db.pkl`\n",
    "\n",
    "Each entry in these lists is a dictionary:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"loc\": \"DDD-LL-WW\",   # word ID\n",
    "    \"word\": \"c-a-p-t-a-i-n\",\n",
    "    \"features\": np.ndarray shape (T, D)  # per-column feature sequence\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9bf616e-ee5e-4caf-9c56-b81ea85dba83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train entries:      2212\n",
      "Validation entries: 1293\n",
      "Keywords:           35\n"
     ]
    }
   ],
   "source": [
    "# Load train / validation feature databases\n",
    "with open(DATA_DIR / \"train_features\" / \"train_db.pkl\", \"rb\") as f:\n",
    "    train_db = pickle.load(f)\n",
    "\n",
    "with open(DATA_DIR / \"validation_features\" / \"validation_db.pkl\", \"rb\") as f:\n",
    "    validation_db = pickle.load(f)\n",
    "\n",
    "# Load keyword list from TSV (one keyword per line)\n",
    "keywords = (DATA_DIR / \"keywords.tsv\").read_text().splitlines()\n",
    "keywords = [k.strip() for k in keywords if k.strip()]\n",
    "\n",
    "print(f\"Train entries:      {len(train_db)}\")\n",
    "print(f\"Validation entries: {len(validation_db)}\")\n",
    "print(f\"Keywords:           {len(keywords)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de05fa1-7002-411c-bff8-2c59de18e3da",
   "metadata": {},
   "source": [
    "## 2. Feature summaries (mean + length)\n",
    "\n",
    "To speed up candidate selection later, we pre-compute for each word:\n",
    "\n",
    "- `feat_mean`: mean feature vector over time (shape `(D,)`)\n",
    "- `length`: number of time steps `T`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761b05f7-a8e0-40f6-8310-e689245d7512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example mean shape: (7,)\n",
      "Example length: 219\n"
     ]
    }
   ],
   "source": [
    "def add_summaries(db):\n",
    "    \"\"\"Add mean vector and length to each entry in-place.\"\"\"\n",
    "    for entry in db:\n",
    "        feats = entry[\"features\"]                # (T, D)\n",
    "        entry[\"feat_mean\"] = feats.mean(axis=0).astype(\"float32\")\n",
    "        entry[\"length\"] = feats.shape[0]         # T\n",
    "\n",
    "add_summaries(train_db)\n",
    "add_summaries(validation_db)\n",
    "\n",
    "print(\"Example mean shape:\", train_db[0][\"feat_mean\"].shape)\n",
    "print(\"Example length:\", train_db[0][\"length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d3171-c3d3-473c-ad33-5685a86696ac",
   "metadata": {},
   "source": [
    "## 3. Helper functions: keyword instances, DTW distance, medoid\n",
    "\n",
    "For each keyword we collect all its training instances and compute a **medoid**\n",
    "(the instance with minimal average DTW distance to the others)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004e0e8b-23cf-407a-9784-5bba59260020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_instances(db, keyword):\n",
    "    \"\"\"Return all entries in db with a given keyword.\"\"\"\n",
    "    return [entry for entry in db if entry[\"word\"] == keyword]\n",
    "\n",
    "\n",
    "def dtw_distance(a_feats, b_feats, win_size=0.2):\n",
    "    \"\"\"\n",
    "    DTW distance between two feature sequences, using the exercise code.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a_feats, b_feats : np.ndarray, shape (T, D)\n",
    "    win_size : float\n",
    "        Sakoe–Chiba band parameter (fraction of sequence length).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        DTW distance.\n",
    "    \"\"\"\n",
    "    return float(dtw.DTW(a_feats, b_feats, win_size=win_size))\n",
    "\n",
    "\n",
    "def keyword_medoid(db, keyword):\n",
    "    \"\"\"\n",
    "    Compute the DTW medoid for a given keyword.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_entry : dict\n",
    "        Representative instance (medoid).\n",
    "    dist_matrix : np.ndarray, shape (n, n)\n",
    "        Pairwise DTW distance matrix between all instances.\n",
    "    \"\"\"\n",
    "    instances = keyword_instances(db, keyword)\n",
    "    n = len(instances)\n",
    "\n",
    "    if n == 0:\n",
    "        raise ValueError(f\"Keyword '{keyword}' not found in train_db.\")\n",
    "\n",
    "    if n == 1:\n",
    "        entry = instances[0]\n",
    "        dist_matrix = np.zeros((1, 1), dtype=float)\n",
    "        return entry, dist_matrix\n",
    "\n",
    "    dist_matrix = np.zeros((n, n), dtype=float)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            d = dtw_distance(instances[i][\"features\"],\n",
    "                             instances[j][\"features\"])\n",
    "            dist_matrix[i, j] = d\n",
    "            dist_matrix[j, i] = d\n",
    "\n",
    "    sums = dist_matrix.sum(axis=1)\n",
    "    best_idx = int(np.argmin(sums))\n",
    "    best_entry = instances[best_idx]\n",
    "\n",
    "    return best_entry, dist_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c46cc24-3252-41b1-921c-4ff7ca95439b",
   "metadata": {},
   "source": [
    "## 4. Build a DTW medoid prototype per keyword\n",
    "\n",
    "For each keyword in `keywords.tsv` we:\n",
    "\n",
    "1. Collect all its training instances.\n",
    "2. Compute the medoid using DTW distances.\n",
    "3. Store the medoid in a `prototypes` dictionary.\n",
    "4. Log basic statistics: support and mean intra-class distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83fb024a-a981-49b3-b3f3-f6b2676c25da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prototypes:  46%|███████████████████████████▉                                 | 16/35 [00:08<00:07,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Keyword 'h-u-n-d-r-e-d' not found in train_db.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prototypes: 100%|█████████████████████████████████████████████████████████████| 35/35 [00:23<00:00,  1.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>support</th>\n",
       "      <th>mean_intra_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C-a-p-t-a-i-n</td>\n",
       "      <td>16</td>\n",
       "      <td>48.376795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>F-o-r-t</td>\n",
       "      <td>14</td>\n",
       "      <td>37.984204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>s_et-c-s_pt</td>\n",
       "      <td>13</td>\n",
       "      <td>20.804661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>O-r-d-e-r-s</td>\n",
       "      <td>12</td>\n",
       "      <td>53.710514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>m-e-n</td>\n",
       "      <td>12</td>\n",
       "      <td>46.850003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          keyword  support  mean_intra_distance\n",
       "19  C-a-p-t-a-i-n       16            48.376795\n",
       "27        F-o-r-t       14            37.984204\n",
       "26    s_et-c-s_pt       13            20.804661\n",
       "18    O-r-d-e-r-s       12            53.710514\n",
       "28          m-e-n       12            46.850003"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototypes = {}\n",
    "stats = []\n",
    "\n",
    "for word in tqdm(keywords, desc=\"Building prototypes\"):\n",
    "    try:\n",
    "        proto, dist_matrix = keyword_medoid(train_db, word)\n",
    "        prototypes[word] = proto\n",
    "\n",
    "        stats.append({\n",
    "            \"keyword\": word,\n",
    "            \"support\": len(keyword_instances(train_db, word)),\n",
    "            \"mean_intra_distance\": float(dist_matrix.mean())\n",
    "                                   if dist_matrix.size > 1 else 0.0,\n",
    "        })\n",
    "    except ValueError as e:\n",
    "        print(\"WARNING:\", e)\n",
    "\n",
    "medoid_df = pd.DataFrame(stats).sort_values(\"support\", ascending=False)\n",
    "medoid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084aaef7-170b-414f-b355-f409cecac908",
   "metadata": {},
   "source": [
    "The table above shows, for each keyword:\n",
    "\n",
    "- `support`: number of training instances (how many times it appears in the training set),\n",
    "- `mean_intra_distance`: average DTW distance between instances of this keyword.\n",
    "\n",
    "Keywords with higher support and lower intra-distance are easier to model; rare keywords with large intra-distance are usually harder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72098401-c7f7-4c87-aecb-e746665b3dca",
   "metadata": {},
   "source": [
    "## 5. Keyword spotting on the validation set\n",
    "\n",
    "For each keyword:\n",
    "\n",
    "1. Take its medoid prototype from `prototypes`.\n",
    "2. Filter validation candidates by **word length** (±30%).\n",
    "3. Rank remaining candidates by Euclidean distance between `feat_mean`.\n",
    "4. Keep the top `K` candidates and run **DTW** on these only.\n",
    "5. Keep the best match (smallest DTW distance).\n",
    "\n",
    "This balances accuracy and runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33751832-07bc-45a1-b052-f61498124bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching validation (DTW + filter):  37%|████████████████▋                            | 13/35 [02:01<03:10,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 'h-u-n-d-r-e-d' - no prototype.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching validation (DTW + filter): 100%|█████████████████████████████████████████████| 35/35 [04:10<00:00,  7.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34,\n",
       " [(39.63474733541498, '304-23-01', 'a-b-o-v-e-s_cm', 'c-a-r-e-f-u-l'),\n",
       "  (54.05357317351873, '302-22-05', 'm-e-n', 'R-e-g-i-m-e-n-t'),\n",
       "  (36.25758829975285, '304-35-07', 'w-i-l-l', 'M-r-s_pt')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "L_TOL = 0.30            # allow ±30% relative length difference\n",
    "TOP_K = 200             # number of best Euclidean candidates to re-score with DTW\n",
    "N_BEST_MATCHES = 20     # number of best DTW matches to keep for visualization\n",
    "\n",
    "predictions = []        # list of (best_dist, best_loc, best_word, keyword)\n",
    "all_top_matches = {}    # dict to store top N-best matches for each keyword\n",
    "\n",
    "for kw in tqdm(keywords, desc=\"Searching validation (DTW + filter)\"):\n",
    "    proto = prototypes.get(kw)\n",
    "    if proto is None:\n",
    "        print(f\"Skipping '{kw}' - no prototype.\")\n",
    "        continue\n",
    "\n",
    "    proto_vec = proto[\"feat_mean\"]\n",
    "    proto_len = proto[\"length\"]\n",
    "\n",
    "    # 1) Candidate filter by length\n",
    "    min_len = int((1.0 - L_TOL) * proto_len)\n",
    "    max_len = int((1.0 + L_TOL) * proto_len)\n",
    "\n",
    "    candidates = []\n",
    "    for entry in validation_db:\n",
    "        L = entry[\"length\"]\n",
    "        if L < min_len or L > max_len:\n",
    "            continue\n",
    "        d_mean = float(norm(proto_vec - entry[\"feat_mean\"]))\n",
    "        candidates.append((d_mean, entry))\n",
    "\n",
    "    # Fallback: if length filter removes everything, use all validation words\n",
    "    if not candidates:\n",
    "        for entry in validation_db:\n",
    "            d_mean = float(norm(proto_vec - entry[\"feat_mean\"]))\n",
    "            candidates.append((d_mean, entry))\n",
    "\n",
    "    # 2) Sort by mean distance and keep TOP_K best\n",
    "    candidates.sort(key=lambda x: x[0])\n",
    "    candidates = [e for _, e in candidates[:TOP_K]]\n",
    "\n",
    "    # 3) Among candidates, use DTW for final distance\n",
    "    best_dist = float(\"inf\")\n",
    "    best_loc = None\n",
    "    best_word = None\n",
    "\n",
    "    dtw_matches = []  # stores all DTW results for this keyword\n",
    "\n",
    "    for entry in candidates:\n",
    "        d = dtw_distance(proto[\"features\"], entry[\"features\"], win_size=0.2)\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_loc = entry[\"loc\"]\n",
    "            best_word = entry[\"word\"]\n",
    "\n",
    "        # Check if current entry matches keyword and store its DTW results\n",
    "        is_correct = (entry[\"word\"] == kw)\n",
    "        dtw_matches.append((d, entry[\"loc\"], entry[\"word\"], is_correct))\n",
    "    \n",
    "    predictions.append((best_dist, best_loc, best_word, kw))\n",
    "\n",
    "    # Sort all scores from DTW matches and keep the N-best matches for visualization\n",
    "    dtw_matches.sort(key=lambda x: x[0])\n",
    "    all_top_matches[kw] = dtw_matches[:N_BEST_MATCHES]\n",
    "\n",
    "len(predictions), predictions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d1853-4124-45eb-bb3d-2c8b56b6573c",
   "metadata": {},
   "source": [
    "## 6. Simple validation metric\n",
    "Here we compute the **top-1 exact match rate**,\n",
    "i.e. the fraction of keywords for which the best validation match has the\n",
    "correct keyword label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbf72df5-2183-4306-895c-c93eafdf8782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 exact keyword match rate on validation: 0.324\n",
      "Keywords with at least one prototype: 34/35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>word</th>\n",
       "      <th>distance</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304-23-01</td>\n",
       "      <td>a-b-o-v-e-s_cm</td>\n",
       "      <td>39.634747</td>\n",
       "      <td>c-a-r-e-f-u-l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302-22-05</td>\n",
       "      <td>m-e-n</td>\n",
       "      <td>54.053573</td>\n",
       "      <td>R-e-g-i-m-e-n-t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304-35-07</td>\n",
       "      <td>w-i-l-l</td>\n",
       "      <td>36.257588</td>\n",
       "      <td>M-r-s_pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304-32-02</td>\n",
       "      <td>O-f-f-i-c-e-r-s</td>\n",
       "      <td>50.360871</td>\n",
       "      <td>O-f-f-i-c-e-r-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>303-16-09</td>\n",
       "      <td>C-a-p-t-a-i-n</td>\n",
       "      <td>58.307667</td>\n",
       "      <td>o-p-p-o-r-t-u-n-i-t-y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    location             word   distance                keyword\n",
       "0  304-23-01   a-b-o-v-e-s_cm  39.634747          c-a-r-e-f-u-l\n",
       "1  302-22-05            m-e-n  54.053573        R-e-g-i-m-e-n-t\n",
       "2  304-35-07          w-i-l-l  36.257588               M-r-s_pt\n",
       "3  304-32-02  O-f-f-i-c-e-r-s  50.360871        O-f-f-i-c-e-r-s\n",
       "4  303-16-09    C-a-p-t-a-i-n  58.307667  o-p-p-o-r-t-u-n-i-t-y"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation: how well do we spot keywords on the validation set?\n",
    "\n",
    "matches = 0\n",
    "total   = 0\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Count how many keywords actually got a prototype\n",
    "n_keywords_total   = len(keywords)\n",
    "n_keywords_protot  = 0\n",
    "\n",
    "for best_dist, best_loc, best_word, kw in predictions:\n",
    "    if best_loc is None:\n",
    "        # this would be the case if something went wrong for a keyword\n",
    "        continue\n",
    "\n",
    "    total += 1\n",
    "    if best_word == kw:\n",
    "        matches += 1\n",
    "\n",
    "    rows.append({\n",
    "        \"location\": best_loc,\n",
    "        \"word\": best_word,\n",
    "        \"distance\": best_dist,\n",
    "        \"keyword\": kw,\n",
    "    })\n",
    "\n",
    "# Any keyword that appears in predictions had a prototype\n",
    "keywords_with_prototype = {kw for _, _, _, kw in predictions if kw is not None}\n",
    "n_keywords_protot = len(keywords_with_prototype)\n",
    "\n",
    "top1_rate = matches / total if total > 0 else 0.0\n",
    "\n",
    "print(f\"Top-1 exact keyword match rate on validation: {top1_rate:.3f}\")\n",
    "print(f\"Keywords with at least one prototype: {n_keywords_protot}/{n_keywords_total}\")\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe9f97-33c7-4a8a-a626-99b5b5ea4eca",
   "metadata": {},
   "source": [
    "### How do we “calculate similarity to all words”?\n",
    "Our implementation therefore uses a **two-stage approximation**:\n",
    "\n",
    "1. **Length filter**  \n",
    "   We restrict the candidates to word images whose sequence length is within ±30% of the prototype’s length.  \n",
    "   If this filter removes all candidates (very rare), we fall back to all validation words.\n",
    "\n",
    "2. **Approximate + exact distance**  \n",
    "   - First we compute a fast **Euclidean distance** between the **mean feature vectors** of prototype and candidate.  \n",
    "   - Then we compute **DTW distance** for all remaining candidates and keep the one with the smallest DTW cost as the best match.\n",
    "\n",
    "So conceptually we still compare the prototype to **all words**, but we:\n",
    "- quickly discard obviously bad candidates using length and Euclidean distance, and use **DTW only where it matters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6785285d-2f6f-45a1-bdb1-9790cb0288fe",
   "metadata": {},
   "source": [
    "## 7. Build `submission.csv` for Kaggle\n",
    "\n",
    "For each detected match we output:\n",
    "\n",
    "- `location`: word ID (`DDD-LL-WW`)\n",
    "- `word`: the **keyword** for which we computed the dissimilarity\n",
    "- `distance`: the DTW distance (smaller = better match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b93b23-c2c8-46e9-8f57-6ca2496f282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    location                   word   distance\n",
      "0  304-23-01          c-a-r-e-f-u-l  39.634747\n",
      "1  302-22-05        R-e-g-i-m-e-n-t  54.053573\n",
      "2  304-35-07               M-r-s_pt  36.257588\n",
      "3  304-32-02        O-f-f-i-c-e-r-s  50.360871\n",
      "4  303-16-09  o-p-p-o-r-t-u-n-i-t-y  58.307667\n",
      "Saved submission to: C:\\Users\\MATEO\\OneDrive\\Personal\\UniFR\\Pattern Recognition\\Group7\\PR_group7\\KWS\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for dist, loc, val_word, kw in predictions:\n",
    "    rows.append({\n",
    "        \"location\": loc,\n",
    "        \"word\": kw,\n",
    "        \"distance\": float(dist),\n",
    "    })\n",
    "\n",
    "submission = pd.DataFrame(rows)\n",
    "print(submission.head())\n",
    "\n",
    "out_path = DATA_DIR / \"submission.csv\"\n",
    "submission.to_csv(out_path, index=False)\n",
    "print(\"Saved submission to:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e1b73-9f45-4603-9b44-2cb1f10a079e",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Our simple KWS system achieves a **top-1 keyword match rate of about 0.32** on the validation set.  \n",
    "This means that for roughly one third of the keywords, the closest match in the validation set (according to our DTW-based similarity) is an occurrence of the **correct keyword**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (msgai-labs)",
   "language": "python",
   "name": "msgai-labs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
